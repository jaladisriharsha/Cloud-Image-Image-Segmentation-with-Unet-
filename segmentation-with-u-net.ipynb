{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-05-16T08:13:40.442455Z",
     "iopub.status.busy": "2022-05-16T08:13:40.442131Z",
     "iopub.status.idle": "2022-05-16T08:13:40.927441Z",
     "shell.execute_reply": "2022-05-16T08:13:40.926555Z",
     "shell.execute_reply.started": "2022-05-16T08:13:40.442408Z"
    }
   },
   "outputs": [],
   "source": [
    "# basic imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-16T08:13:41.721558Z",
     "iopub.status.busy": "2022-05-16T08:13:41.7212Z",
     "iopub.status.idle": "2022-05-16T08:13:44.494199Z",
     "shell.execute_reply": "2022-05-16T08:13:44.49336Z",
     "shell.execute_reply.started": "2022-05-16T08:13:41.721494Z"
    }
   },
   "outputs": [],
   "source": [
    "# tensorflow imports\n",
    "from tensorflow import reduce_sum\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, Conv2DTranspose, MaxPool2D, Dropout, concatenate, Flatten\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-16T08:13:45.486103Z",
     "iopub.status.busy": "2022-05-16T08:13:45.485788Z",
     "iopub.status.idle": "2022-05-16T08:13:45.491796Z",
     "shell.execute_reply": "2022-05-16T08:13:45.490314Z",
     "shell.execute_reply.started": "2022-05-16T08:13:45.486051Z"
    }
   },
   "outputs": [],
   "source": [
    "# image directory paths \n",
    "data_path = '../input/understanding_cloud_organization'\n",
    "train_csv_path = os.path.join('../input/understanding_cloud_organization','train.csv')\n",
    "train_image_path = os.path.join('../input/understanding_cloud_organization','train_images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-16T08:13:46.483953Z",
     "iopub.status.busy": "2022-05-16T08:13:46.48361Z",
     "iopub.status.idle": "2022-05-16T08:13:46.489492Z",
     "shell.execute_reply": "2022-05-16T08:13:46.488457Z",
     "shell.execute_reply.started": "2022-05-16T08:13:46.483896Z"
    }
   },
   "outputs": [],
   "source": [
    "# network configuration parameters\n",
    "# original image is 1600x256, so we will resize it\n",
    "img_w = 384 # resized weidth\n",
    "img_h = 256 # resized height\n",
    "batch_size = 10\n",
    "epochs = 10\n",
    "# batch size for training unet\n",
    "k_size = 3 # kernel size 3x3\n",
    "val_size = .20 # split of training set between train and validation set\n",
    "# network hyper parameters\n",
    "smooth = 1.\n",
    "dropout_rate = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-16T08:13:47.886369Z",
     "iopub.status.busy": "2022-05-16T08:13:47.886068Z",
     "iopub.status.idle": "2022-05-16T08:13:47.89146Z",
     "shell.execute_reply": "2022-05-16T08:13:47.890621Z",
     "shell.execute_reply.started": "2022-05-16T08:13:47.886319Z"
    }
   },
   "outputs": [],
   "source": [
    "# saving and loading model\n",
    "load_pretrained_model = False # load a pre-trained model\n",
    "save_model = True # save the model after training\n",
    "pretrained_model_path = './nested_unet.h5' # path of pretrained model\n",
    "model_save_path = './nested_unet.h5' # path of model to save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data & Utility Functions\n",
    "\n",
    "In this section, we will load the metadata about the image into pandas dataframe. We will also process it a little bit to make our life easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-16T08:13:51.321275Z",
     "iopub.status.busy": "2022-05-16T08:13:51.320939Z",
     "iopub.status.idle": "2022-05-16T08:13:54.954843Z",
     "shell.execute_reply": "2022-05-16T08:13:54.954102Z",
     "shell.execute_reply.started": "2022-05-16T08:13:51.32122Z"
    }
   },
   "outputs": [],
   "source": [
    "# load full data and label no mask as -1\n",
    "train_df = pd.read_csv(train_csv_path).fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-16T08:14:00.097251Z",
     "iopub.status.busy": "2022-05-16T08:14:00.096659Z",
     "iopub.status.idle": "2022-05-16T08:14:00.130544Z",
     "shell.execute_reply": "2022-05-16T08:14:00.129589Z",
     "shell.execute_reply.started": "2022-05-16T08:14:00.097194Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-16T08:14:01.873815Z",
     "iopub.status.busy": "2022-05-16T08:14:01.873222Z",
     "iopub.status.idle": "2022-05-16T08:14:02.750819Z",
     "shell.execute_reply": "2022-05-16T08:14:02.749799Z",
     "shell.execute_reply.started": "2022-05-16T08:14:01.873548Z"
    }
   },
   "outputs": [],
   "source": [
    "# image id and class id are two seperate entities and it makes it easier to split them up in two columns\n",
    "train_df['ImageId'] = train_df['Image_Label'].apply(lambda x: x.split('_')[0])\n",
    "train_df['Label'] = train_df['Image_Label'].apply(lambda x: x.split('_')[1])\n",
    "# lets create a dict with class id and encoded pixels and group all the defaults per image\n",
    "train_df['Label_EncodedPixels'] = train_df.apply(lambda row: (row['Label'], row['EncodedPixels']), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-16T08:14:03.839644Z",
     "iopub.status.busy": "2022-05-16T08:14:03.839302Z",
     "iopub.status.idle": "2022-05-16T08:14:03.857519Z",
     "shell.execute_reply": "2022-05-16T08:14:03.856633Z",
     "shell.execute_reply.started": "2022-05-16T08:14:03.839584Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-16T08:14:04.978344Z",
     "iopub.status.busy": "2022-05-16T08:14:04.978042Z",
     "iopub.status.idle": "2022-05-16T08:14:05.703697Z",
     "shell.execute_reply": "2022-05-16T08:14:05.702516Z",
     "shell.execute_reply.started": "2022-05-16T08:14:04.978293Z"
    }
   },
   "outputs": [],
   "source": [
    "# group together all masks for each image\n",
    "grouped_EncodedPixels = train_df.groupby('ImageId')['Label_EncodedPixels'].apply(list)\n",
    "grouped_EncodedPixels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utility Functions for RLE Encoding & Decoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-16T08:15:52.719603Z",
     "iopub.status.busy": "2022-05-16T08:15:52.719234Z",
     "iopub.status.idle": "2022-05-16T08:15:52.728912Z",
     "shell.execute_reply": "2022-05-16T08:15:52.727937Z",
     "shell.execute_reply.started": "2022-05-16T08:15:52.719545Z"
    }
   },
   "outputs": [],
   "source": [
    "# from https://www.kaggle.com/robertkag/rle-to-mask-converter\n",
    "def rle_to_mask(rle_string,height,width):\n",
    "    '''\n",
    "    convert RLE(run length encoding) string to numpy array\n",
    "\n",
    "    Parameters: \n",
    "    rleString (str): Description of arg1 \n",
    "    height (int): height of the mask\n",
    "    width (int): width of the mask \n",
    "\n",
    "    Returns: \n",
    "    numpy.array: numpy array of the mask\n",
    "    '''\n",
    "    rows, cols = height, width\n",
    "    if rle_string == -1:\n",
    "        return np.zeros((height, width))\n",
    "    else:\n",
    "        rleNumbers = [int(numstring) for numstring in rle_string.split(' ')]\n",
    "        rlePairs = np.array(rleNumbers).reshape(-1,2)\n",
    "        img = np.zeros(rows*cols,dtype=np.uint8)\n",
    "        for index,length in rlePairs:\n",
    "            index -= 1\n",
    "            img[index:index+length] = 255\n",
    "        img = img.reshape(cols,rows)\n",
    "        img = img.T\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-16T08:15:57.387499Z",
     "iopub.status.busy": "2022-05-16T08:15:57.387197Z",
     "iopub.status.idle": "2022-05-16T08:15:57.39422Z",
     "shell.execute_reply": "2022-05-16T08:15:57.393165Z",
     "shell.execute_reply.started": "2022-05-16T08:15:57.38745Z"
    }
   },
   "outputs": [],
   "source": [
    "# Thanks to the authors of: https://www.kaggle.com/paulorzp/rle-functions-run-lenght-encode-decode\n",
    "def mask_to_rle(mask):\n",
    "    '''\n",
    "    Convert a mask into RLE\n",
    "    \n",
    "    \n",
    "    Parameters: \n",
    "    mask (numpy.array): binary mask of numpy array where 1 - mask, 0 - background\n",
    "\n",
    "    Returns: \n",
    "    sring: run length encoding \n",
    "    '''\n",
    "    pixels= mask.T.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-16T08:16:10.588264Z",
     "iopub.status.busy": "2022-05-16T08:16:10.587897Z",
     "iopub.status.idle": "2022-05-16T08:16:10.621175Z",
     "shell.execute_reply": "2022-05-16T08:16:10.620079Z",
     "shell.execute_reply.started": "2022-05-16T08:16:10.588219Z"
    }
   },
   "outputs": [],
   "source": [
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, list_ids, labels, image_dir, batch_size=32,\n",
    "                 img_h=256, img_w=512, shuffle=True):\n",
    "        \n",
    "        self.list_ids = list_ids\n",
    "        self.labels = labels\n",
    "        self.image_dir = image_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.img_h = img_h\n",
    "        self.img_w = img_w\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "    \n",
    "    def __len__(self):\n",
    "        'denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_ids)) / self.batch_size)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        'generate one batch of data'\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        # get list of IDs\n",
    "        list_ids_temp = [self.list_ids[k] for k in indexes]\n",
    "        # generate data\n",
    "        X, y = self.__data_generation(list_ids_temp)\n",
    "        # return data \n",
    "        return X, y\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        'update ended after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_ids))\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "            \n",
    "    def __data_generation(self, list_ids_temp):\n",
    "        'generate data containing batch_size samples'\n",
    "        X = np.empty((self.batch_size, self.img_h, self.img_w, 1))\n",
    "        y = np.empty((self.batch_size, self.img_h, self.img_w, 4))\n",
    "        \n",
    "        for idx, id in enumerate(list_ids_temp):\n",
    "            file_path =  os.path.join(self.image_dir, id)\n",
    "            image = cv2.imread(file_path, 0)\n",
    "            image_resized = cv2.resize(image, (self.img_w, self.img_h))\n",
    "            image_resized = np.array(image_resized, dtype=np.float64)\n",
    "            # standardization of the image\n",
    "            image_resized -= image_resized.mean()\n",
    "            image_resized /= image_resized.std()\n",
    "            \n",
    "            mask = np.empty((img_h, img_w, 4))\n",
    "            \n",
    "            for idm, image_class in enumerate(['Fish', 'Flower', 'Gravel', 'Sugar']):\n",
    "                rle = self.labels.get(id + '_' + image_class)\n",
    "                # if there is no mask create empty mask\n",
    "                if rle is None:\n",
    "                    class_mask = np.zeros((2100, 1400))\n",
    "                else:\n",
    "                    class_mask = rle_to_mask(rle, width=2100, height=1400)\n",
    "             \n",
    "                class_mask_resized = cv2.resize(class_mask, (self.img_w, self.img_h))\n",
    "                mask[...,idm] = class_mask_resized\n",
    "            \n",
    "            X[idx,] = np.expand_dims(image_resized, axis=2)\n",
    "            y[idx,] = mask\n",
    "        \n",
    "        # normalize Y\n",
    "        y = (y > 0).astype(int)\n",
    "            \n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-16T08:16:14.169671Z",
     "iopub.status.busy": "2022-05-16T08:16:14.169346Z",
     "iopub.status.idle": "2022-05-16T08:16:14.179369Z",
     "shell.execute_reply": "2022-05-16T08:16:14.178586Z",
     "shell.execute_reply.started": "2022-05-16T08:16:14.169616Z"
    }
   },
   "outputs": [],
   "source": [
    "# split the training data into train and validation set (stratified)\n",
    "train_image_ids = train_df['ImageId'].unique()\n",
    "X_train, X_val = train_test_split(train_image_ids, test_size=val_size, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-16T08:16:16.320594Z",
     "iopub.status.busy": "2022-05-16T08:16:16.320261Z",
     "iopub.status.idle": "2022-05-16T08:16:17.899434Z",
     "shell.execute_reply": "2022-05-16T08:16:17.898626Z",
     "shell.execute_reply.started": "2022-05-16T08:16:16.320538Z"
    }
   },
   "outputs": [],
   "source": [
    "# create a dict of all the masks\n",
    "masks = {}\n",
    "for index, row in train_df[train_df['EncodedPixels']!=-1].iterrows():\n",
    "    masks[row['Image_Label']] = row['EncodedPixels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-16T08:16:20.02719Z",
     "iopub.status.busy": "2022-05-16T08:16:20.026825Z",
     "iopub.status.idle": "2022-05-16T08:16:20.035161Z",
     "shell.execute_reply": "2022-05-16T08:16:20.034045Z",
     "shell.execute_reply.started": "2022-05-16T08:16:20.027133Z"
    }
   },
   "outputs": [],
   "source": [
    "params = {'img_h': img_h,\n",
    "          'img_w': img_w,\n",
    "          'image_dir': train_image_path,\n",
    "          'batch_size': batch_size,\n",
    "          'shuffle': True}\n",
    "\n",
    "# Get Generators\n",
    "training_generator = DataGenerator(X_train, masks, **params)\n",
    "validation_generator = DataGenerator(X_val, masks, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-16T08:16:23.002644Z",
     "iopub.status.busy": "2022-05-16T08:16:23.002296Z",
     "iopub.status.idle": "2022-05-16T08:16:24.127478Z",
     "shell.execute_reply": "2022-05-16T08:16:24.125969Z",
     "shell.execute_reply.started": "2022-05-16T08:16:23.002585Z"
    }
   },
   "outputs": [],
   "source": [
    "# check out the shapes\n",
    "x, y = training_generator.__getitem__(0)\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-16T08:16:25.647231Z",
     "iopub.status.busy": "2022-05-16T08:16:25.646702Z",
     "iopub.status.idle": "2022-05-16T08:16:25.656211Z",
     "shell.execute_reply": "2022-05-16T08:16:25.654409Z",
     "shell.execute_reply.started": "2022-05-16T08:16:25.647122Z"
    }
   },
   "outputs": [],
   "source": [
    "# visualize cloud image with four classes of faults in seperate columns\n",
    "def viz_cloud_img_mask(img, masks):\n",
    "    img = cv2.cvtColor(img.astype('float32'), cv2.COLOR_BGR2RGB)\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=4, sharey=True, figsize=(20,10))\n",
    "    cmaps = [\"Reds\", \"Blues\", \"Greens\", \"Purples\"]\n",
    "    for idx, mask in enumerate(masks):\n",
    "        ax[idx].imshow(img)\n",
    "        ax[idx].imshow(mask, alpha=0.3, cmap=cmaps[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-16T08:16:28.309603Z",
     "iopub.status.busy": "2022-05-16T08:16:28.309254Z",
     "iopub.status.idle": "2022-05-16T08:16:36.06271Z",
     "shell.execute_reply": "2022-05-16T08:16:36.061822Z",
     "shell.execute_reply.started": "2022-05-16T08:16:28.309544Z"
    }
   },
   "outputs": [],
   "source": [
    "# lets visualize some images with their cloud formation mask to make sure our data generator is working like it should\n",
    "for ix in range(0,batch_size):\n",
    "    if y[ix].sum() > 0:\n",
    "        img = x[ix]\n",
    "        masks_temp = [y[ix][...,i] for i in range(0,4)]\n",
    "        viz_cloud_img_mask(img, masks_temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UNet++: A Nested U-Net Architecture\n",
    "\n",
    "\n",
    "\n",
    "![UNet++: A Nested U-Net Architecture](https://miro.medium.com/max/658/1*ExIkm6cImpPgpetFW1kwyQ.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-16T08:17:00.263475Z",
     "iopub.status.busy": "2022-05-16T08:17:00.263186Z",
     "iopub.status.idle": "2022-05-16T08:17:00.271306Z",
     "shell.execute_reply": "2022-05-16T08:17:00.270262Z",
     "shell.execute_reply.started": "2022-05-16T08:17:00.263427Z"
    }
   },
   "outputs": [],
   "source": [
    "def standard_unit(input_tensor, stage, nb_filter, kernel_size=3):\n",
    "\n",
    "    act = 'elu'\n",
    "\n",
    "    x = Conv2D(nb_filter, (kernel_size, kernel_size), activation=act, name='conv'+stage+'_1', kernel_initializer = 'he_normal', padding='same', kernel_regularizer=l2(1e-4))(input_tensor)\n",
    "    x = Dropout(dropout_rate, name='dp'+stage+'_1')(x)\n",
    "    x = Conv2D(nb_filter, (kernel_size, kernel_size), activation=act, name='conv'+stage+'_2', kernel_initializer = 'he_normal', padding='same', kernel_regularizer=l2(1e-4))(x)\n",
    "    x = Dropout(dropout_rate, name='dp'+stage+'_2')(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-16T08:17:18.322266Z",
     "iopub.status.busy": "2022-05-16T08:17:18.321929Z",
     "iopub.status.idle": "2022-05-16T08:17:18.36082Z",
     "shell.execute_reply": "2022-05-16T08:17:18.359907Z",
     "shell.execute_reply.started": "2022-05-16T08:17:18.322211Z"
    }
   },
   "outputs": [],
   "source": [
    "def Nest_Net(img_rows, img_cols, color_type=1, num_class=1, deep_supervision=False):\n",
    "\n",
    "    nb_filter = [32,64,128,256,512]\n",
    "    act = 'elu'\n",
    "\n",
    "    bn_axis = 3\n",
    "    img_input = Input(shape=(img_rows, img_cols, color_type), name='main_input')\n",
    "\n",
    "    conv1_1 = standard_unit(img_input, stage='11', nb_filter=nb_filter[0])\n",
    "    pool1 = MaxPool2D((2, 2), strides=(2, 2), name='pool1')(conv1_1)\n",
    "\n",
    "    conv2_1 = standard_unit(pool1, stage='21', nb_filter=nb_filter[1])\n",
    "    pool2 = MaxPool2D((2, 2), strides=(2, 2), name='pool2')(conv2_1)\n",
    "\n",
    "    up1_2 = Conv2DTranspose(nb_filter[0], (2, 2), strides=(2, 2), name='up12', padding='same')(conv2_1)\n",
    "    conv1_2 = concatenate([up1_2, conv1_1], name='merge12', axis=bn_axis)\n",
    "    conv1_2 = standard_unit(conv1_2, stage='12', nb_filter=nb_filter[0])\n",
    "\n",
    "    conv3_1 = standard_unit(pool2, stage='31', nb_filter=nb_filter[2])\n",
    "    pool3 = MaxPool2D((2, 2), strides=(2, 2), name='pool3')(conv3_1)\n",
    "\n",
    "    up2_2 = Conv2DTranspose(nb_filter[1], (2, 2), strides=(2, 2), name='up22', padding='same')(conv3_1)\n",
    "    conv2_2 = concatenate([up2_2, conv2_1], name='merge22', axis=bn_axis)\n",
    "    conv2_2 = standard_unit(conv2_2, stage='22', nb_filter=nb_filter[1])\n",
    "\n",
    "    up1_3 = Conv2DTranspose(nb_filter[0], (2, 2), strides=(2, 2), name='up13', padding='same')(conv2_2)\n",
    "    conv1_3 = concatenate([up1_3, conv1_1, conv1_2], name='merge13', axis=bn_axis)\n",
    "    conv1_3 = standard_unit(conv1_3, stage='13', nb_filter=nb_filter[0])\n",
    "\n",
    "    conv4_1 = standard_unit(pool3, stage='41', nb_filter=nb_filter[3])\n",
    "    pool4 = MaxPool2D((2, 2), strides=(2, 2), name='pool4')(conv4_1)\n",
    "\n",
    "    up3_2 = Conv2DTranspose(nb_filter[2], (2, 2), strides=(2, 2), name='up32', padding='same')(conv4_1)\n",
    "    conv3_2 = concatenate([up3_2, conv3_1], name='merge32', axis=bn_axis)\n",
    "    conv3_2 = standard_unit(conv3_2, stage='32', nb_filter=nb_filter[2])\n",
    "\n",
    "    up2_3 = Conv2DTranspose(nb_filter[1], (2, 2), strides=(2, 2), name='up23', padding='same')(conv3_2)\n",
    "    conv2_3 = concatenate([up2_3, conv2_1, conv2_2], name='merge23', axis=bn_axis)\n",
    "    conv2_3 = standard_unit(conv2_3, stage='23', nb_filter=nb_filter[1])\n",
    "\n",
    "    up1_4 = Conv2DTranspose(nb_filter[0], (2, 2), strides=(2, 2), name='up14', padding='same')(conv2_3)\n",
    "    conv1_4 = concatenate([up1_4, conv1_1, conv1_2, conv1_3], name='merge14', axis=bn_axis)\n",
    "    conv1_4 = standard_unit(conv1_4, stage='14', nb_filter=nb_filter[0])\n",
    "\n",
    "    conv5_1 = standard_unit(pool4, stage='51', nb_filter=nb_filter[4])\n",
    "\n",
    "    up4_2 = Conv2DTranspose(nb_filter[3], (2, 2), strides=(2, 2), name='up42', padding='same')(conv5_1)\n",
    "    conv4_2 = concatenate([up4_2, conv4_1], name='merge42', axis=bn_axis)\n",
    "    conv4_2 = standard_unit(conv4_2, stage='42', nb_filter=nb_filter[3])\n",
    "\n",
    "    up3_3 = Conv2DTranspose(nb_filter[2], (2, 2), strides=(2, 2), name='up33', padding='same')(conv4_2)\n",
    "    conv3_3 = concatenate([up3_3, conv3_1, conv3_2], name='merge33', axis=bn_axis)\n",
    "    conv3_3 = standard_unit(conv3_3, stage='33', nb_filter=nb_filter[2])\n",
    "\n",
    "    up2_4 = Conv2DTranspose(nb_filter[1], (2, 2), strides=(2, 2), name='up24', padding='same')(conv3_3)\n",
    "    conv2_4 = concatenate([up2_4, conv2_1, conv2_2, conv2_3], name='merge24', axis=bn_axis)\n",
    "    conv2_4 = standard_unit(conv2_4, stage='24', nb_filter=nb_filter[1])\n",
    "\n",
    "    up1_5 = Conv2DTranspose(nb_filter[0], (2, 2), strides=(2, 2), name='up15', padding='same')(conv2_4)\n",
    "    conv1_5 = concatenate([up1_5, conv1_1, conv1_2, conv1_3, conv1_4], name='merge15', axis=bn_axis)\n",
    "    conv1_5 = standard_unit(conv1_5, stage='15', nb_filter=nb_filter[0])\n",
    "\n",
    "    nestnet_output_1 = Conv2D(num_class, (1, 1), activation='sigmoid', name='output_1', kernel_initializer = 'he_normal', padding='same', kernel_regularizer=l2(1e-4))(conv1_2)\n",
    "    nestnet_output_2 = Conv2D(num_class, (1, 1), activation='sigmoid', name='output_2', kernel_initializer = 'he_normal', padding='same', kernel_regularizer=l2(1e-4))(conv1_3)\n",
    "    nestnet_output_3 = Conv2D(num_class, (1, 1), activation='sigmoid', name='output_3', kernel_initializer = 'he_normal', padding='same', kernel_regularizer=l2(1e-4))(conv1_4)\n",
    "    nestnet_output_4 = Conv2D(num_class, (1, 1), activation='sigmoid', name='output_4', kernel_initializer = 'he_normal', padding='same', kernel_regularizer=l2(1e-4))(conv1_5)\n",
    "\n",
    "    if deep_supervision:\n",
    "        model = Model(img_input, [nestnet_output_1,nestnet_output_2,nestnet_output_3,nestnet_output_4])\n",
    "    else:\n",
    "        model = Model(img_input, [nestnet_output_4])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-16T08:17:35.206953Z",
     "iopub.status.busy": "2022-05-16T08:17:35.206564Z",
     "iopub.status.idle": "2022-05-16T08:17:35.215192Z",
     "shell.execute_reply": "2022-05-16T08:17:35.214208Z",
     "shell.execute_reply.started": "2022-05-16T08:17:35.206892Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dice similarity coefficient loss, brought to you by: https://github.com/nabsabraham/focal-tversky-unet\n",
    "def dsc(y_true, y_pred):\n",
    "    smooth = 1.\n",
    "    y_true_f = Flatten()(y_true)\n",
    "    y_pred_f = Flatten()(y_pred)\n",
    "    intersection = reduce_sum(y_true_f * y_pred_f)\n",
    "    score = (2. * intersection + smooth) / (reduce_sum(y_true_f) + reduce_sum(y_pred_f) + smooth)\n",
    "    return score\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    loss = 1 - dsc(y_true, y_pred)\n",
    "    return loss\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    loss = binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-16T08:17:41.928969Z",
     "iopub.status.busy": "2022-05-16T08:17:41.928492Z",
     "iopub.status.idle": "2022-05-16T08:17:44.076753Z",
     "shell.execute_reply": "2022-05-16T08:17:44.076011Z",
     "shell.execute_reply.started": "2022-05-16T08:17:41.92888Z"
    }
   },
   "outputs": [],
   "source": [
    "# get an instance of the model\n",
    "model = Nest_Net(img_h, img_w, color_type=1, num_class=4, deep_supervision=False)\n",
    "# define optimizer \n",
    "adam = Adam(lr = 0.05, epsilon = 0.1)\n",
    "model.compile(optimizer=adam, loss=bce_dice_loss, metrics=[dice_loss])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-16T08:17:44.695868Z",
     "iopub.status.busy": "2022-05-16T08:17:44.695524Z",
     "iopub.status.idle": "2022-05-16T08:17:44.701508Z",
     "shell.execute_reply": "2022-05-16T08:17:44.70053Z",
     "shell.execute_reply.started": "2022-05-16T08:17:44.695811Z"
    }
   },
   "outputs": [],
   "source": [
    "if load_pretrained_model:\n",
    "    try:\n",
    "        model.load_weights(pretrained_model_path)\n",
    "        print('pre-trained model loaded!')\n",
    "    except OSError:\n",
    "        print('You need to run the model and load the trained model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-16T08:17:48.354308Z",
     "iopub.status.busy": "2022-05-16T08:17:48.353982Z",
     "iopub.status.idle": "2022-05-16T09:21:25.993588Z",
     "shell.execute_reply": "2022-05-16T09:21:25.990156Z",
     "shell.execute_reply.started": "2022-05-16T08:17:48.354257Z"
    }
   },
   "outputs": [],
   "source": [
    "history = model.fit_generator(generator=training_generator, validation_data=validation_generator, epochs=epochs, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-16T09:22:18.652197Z",
     "iopub.status.busy": "2022-05-16T09:22:18.651876Z",
     "iopub.status.idle": "2022-05-16T09:22:21.584918Z",
     "shell.execute_reply": "2022-05-16T09:22:21.584149Z",
     "shell.execute_reply.started": "2022-05-16T09:22:18.652145Z"
    }
   },
   "outputs": [],
   "source": [
    "if save_model: \n",
    "    model.save(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-16T09:27:01.905025Z",
     "iopub.status.busy": "2022-05-16T09:27:01.904688Z",
     "iopub.status.idle": "2022-05-16T09:27:01.912225Z",
     "shell.execute_reply": "2022-05-16T09:27:01.911122Z",
     "shell.execute_reply.started": "2022-05-16T09:27:01.904969Z"
    }
   },
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-16T09:31:16.015237Z",
     "iopub.status.busy": "2022-05-16T09:31:16.014933Z",
     "iopub.status.idle": "2022-05-16T09:31:16.166591Z",
     "shell.execute_reply": "2022-05-16T09:31:16.165752Z",
     "shell.execute_reply.started": "2022-05-16T09:31:16.015184Z"
    }
   },
   "outputs": [],
   "source": [
    "pred = model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-16T09:31:30.967065Z",
     "iopub.status.busy": "2022-05-16T09:31:30.966342Z",
     "iopub.status.idle": "2022-05-16T09:31:38.563361Z",
     "shell.execute_reply": "2022-05-16T09:31:38.56268Z",
     "shell.execute_reply.started": "2022-05-16T09:31:30.967006Z"
    }
   },
   "outputs": [],
   "source": [
    "for ix in range(0,batch_size):\n",
    "    if pred[ix].sum() > 0:\n",
    "        img = x[ix]\n",
    "        masks_temp = [pred[ix][...,i] for i in range(0,4)]\n",
    "        viz_cloud_img_mask(img, masks_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-15T15:36:27.850631Z",
     "iopub.status.busy": "2022-05-15T15:36:27.850397Z",
     "iopub.status.idle": "2022-05-15T15:36:27.966466Z",
     "shell.execute_reply": "2022-05-15T15:36:27.964134Z",
     "shell.execute_reply.started": "2022-05-15T15:36:27.850588Z"
    }
   },
   "outputs": [],
   "source": [
    "# summarize history for accuracy\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['dice_loss'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "\n",
    "# summarize history for loss\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.plot(history.history['val_dice_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
